function fitness = evaluateMAFitness(data, chromo, nFolds, useLBFGS)
    % Evaluates the fitness of the given chromosome (weight matrix) using the
    % given data

    if nargin < 3
        nFolds = 5;
        useLBFGS = true;
    end

    % Do L-BFGS on the chromosome for a few iterations

    % Set parameters to L-BFGS
    sparsityParam = 0.1;   % desired average activation of the hidden units.
                           % (This was denoted by the Greek alphabet rho, which looks like a lower-case "p",
                                   %  in the lecture notes). 
    lambda = 3e-3;         % weight decay parameter       
    beta = 3;              % weight of sparsity penalty term       
    maxIter = 2;

    autoEncoder = chromo.autoEncoder;

    %  Use minFunc to minimize the function
    addpath minFunc/
    options.Method = 'lbfgs'; % Here, we use L-BFGS to optimize our cost
                              % function. Generally, for minFunc to work, you
                              % need a function pointer with two outputs: the
                              % function value and the gradient. In our problem,
                              % sparseAutoencoderCost.m satisfies this.
    options.maxIter = maxIter;	  % Maximum number of iterations of L-BFGS to run 
    options.display = 'on';

    if use
    % Run L-BFGS on the autoEncoder 
    [autoEncoderTheta, cost] = minFunc( @(p) sparseAutoencoderCost(p, ...
                                       chromo.inputLayerSize, chromo.hiddenLayerSize, ...
                                       lambda, sparsityParam, ...
                                       beta, vertcat(data.image)'), ...
                                       autoEncoder, options);
autoEncoderTheta = autoEncoder;
    % Get reconstruction error for all samples
    reconstruction = reconstructFromAutoencoder(autoEncoderTheta, chromo.hiddenLayerSize,...
                                                chromo.inputLayerSize, vertcat(data.image)');
    error = mean(sum((reconstruction - vertcat(data.image)').^2));
    fitness = exp(-error/1000);
%     % Evaluate performance of tuned auto encoder matrix using cross-fold
%     % validation classification performance using an SVM
%     accuracy = zeros(nFolds, 1);
%     for i = 1:nFolds
%         % Build train and test datasets
%         testRange = floor((i-1)*nSamples/nFolds)+1:floor(i*nSamples/nFolds);
%         trainRange = 1:nSamples;
%         trainRange(testRange) = [];
%         
%         % Take intersections of test and train ranges with samplesubset
%         testRange = intersect(testRange, sampleSubset);
%         trainRange = intersect(trainRange, sampleSubset);
% 
%         % Compute features for this fold's training set
%         features = feedForwardAutoencoder(autoEncoderTheta, length(autoEncoderTheta),...
%                                           size(data, 2), trainData);
%                 
%         % Train SVM on trainRange
%         model = trainSVMinstances(labels(trainRange), features(trainRange, :),...
%                                   '-b 1');
%         % Test SVM on testRange
%         accuracy(i) = testSVMinstances(model, labels(testRange),...
%                                        features(testRange, :), '-b 1');
%     end
% 
%     % Compute fitness as the average classification accuracy
%     fitness = mean(accuracy);
end
